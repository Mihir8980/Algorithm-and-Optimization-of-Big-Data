{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment3.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"t0hcZCAaT7pd"},"source":["# Multiple Linear Regression Using Normal Equation\n","(Generalization of Simple Linear Regression)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7ZTGqi3S9DEk"},"source":["## Formula of Normal Equation Method :\n","\n","$\\theta = {(X^TX)}^{-1}(X^Ty)$ \n","\n","where $\\theta$ are the parameters, \n","$X$ is input matrix, \n","$y$ is output label"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vpkKgUls9DEo","outputId":"e7c35ac2-1c11-4b4d-e19b-5b84ca538654","colab":{}},"source":["# MultiVariable Linear Regression Using Normal Equation Method\n","\n","# Importing Required Libraries\n","import numpy as np\n","from sklearn.datasets import load_boston #DATASET\n","from numpy.linalg import pinv,inv,LinAlgError \n","from sklearn import metrics\n","\n","# Loading Boston Dataset\n","X,y = load_boston(return_X_y=True)\n","\n","# Forming Xtrain and ytrain\n","X_train_temp1 = X[0:400,:]      # Taking top 400 rows of X for training\n","dummy = np.ones((X_train_temp1.shape[0],1))   # dummy variable column\n","X_train = np.c_[dummy,X_train_temp1]     # Forming Xtrain - Stacking dummy variable with Xtrain\n","y_train = y[0:400]   # Forming ytrain - taking top 400 rows of y for training\n","\n","# Taking rows from 401 till end for testing\n","X_test_temp1 = X[400:,:]        # Taking rows from 401 till end of X for training\n","dummy1 = np.ones((X_test_temp1.shape[0],1))   # dummy variable column\n","X_test = np.c_[dummy1,X_test_temp1]   # Forming Xtest - Stacking dummy variable with Xtest\n","y_test = y[400:]   # Forming ytest - taking from 401 till end of y for training\n","\n","theta = np.zeros((X.shape[1],1))   # assigning theta to all zeros\n","XTX = np.dot(X_train.T,X_train)    # computing Xtrain.T*Xtrain (on training set) \n","\n","try:\n","    XTXi = inv(XTX)    # computing inverse of X.T*X if invertible\n","except:\n","    XTXi = pinv(XTX)   # computing psuedo inverse of X.T*X \n","\n","XTy = np.dot(X_train.T,y_train)    # Computing X.T*y\n","\n","theta = np.dot(XTXi,XTy)          # Computing theta by multiplying X.T*X and X.T*y\n","predictions = np.dot(theta,X_test.T)  # Computing predictions on testing set \n","\n","# Mean Squared and Mean Absoluete Error\n","print(\"Mean Squared Error: \",metrics.mean_squared_error(y_test,predictions))\n","print(\"Mean Absolute Error: \",metrics.mean_absolute_error(y_test,predictions))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mean Squared Error:  37.89377859959266\n","Mean Absolute Error:  5.142232214464803\n"],"name":"stdout"}]}]}